# jb_test_task

Привет. Я писал вопрос по заданию, где пытался понять, какие от нас хотят слои. В итоге сделал 4 512 512 4 (входной скрытый скрытый выходой соответственно). Bias просто прибавляется перед применением функции активации при переходе на каждый следующий слой.
В принципе, в коде это легко перенастроить, если интересно что-то померить по времени.<br/><br/>
Написал относительно интуитивную архитектуру. Какие-то места можно было сделать более общими, но раз в задании требовалось решить конкретную задачу, 
я решил прям совсем в решение маштабируемой задачи не углубляться. <br/><br/>
В коде оставленны комментарии на всякий случай. Основной класс нейронки, собственно, NeuralNetwork, где и решается задача.
